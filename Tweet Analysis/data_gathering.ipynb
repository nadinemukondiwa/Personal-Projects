{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting tweets about Korean Dramas\n",
    "A few years ago, I started watching Korean dramas. While I have never posted about them online, I was interested in analyzing different tweets with the hashtag \"#kdrama\" and #netflix. [Twitter Search API](https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import tweepy\n",
    "import emojis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "consumer_key = ''xxxxxxxxxxxxx''\n",
    "consumer_secret =''xxxxxxxxxxxxx''\n",
    "access_token = ''xxxxxxxxxxxxx''\n",
    "access_token_secret =''xxxxxxxxxxxxx''\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "#The search term you want to find\n",
    "query = '%23netflix%20(%23kdrama%20OR%20%23koreandrama%20OR%20%23kdramas)'\n",
    "\n",
    "#Calling the user_timeline function with our parameters\n",
    "results_1 = api.search(q = query, result_type = 'recent', count = 100, lang = 'en', include_entities = True)\n",
    "results_2 = api.search(q = query, result_type = 'recent', count = 100, lang = 'en', include_entities = True, max_id = 1355164636417409035)\n",
    "results_3 = api.search(q = query, result_type = 'recent', count = 100, lang = 'en', include_entities = True, max_id = 1354550627926482944)\n",
    "results_4 = api.search(q = query, result_type = 'recent', count = 100, lang = 'en', include_entities = True, max_id = 1354174810851577865)\n",
    "results_5 = api.search(q = query, result_type = 'recent', count = 100, lang = 'en', include_entities = True, max_id = 1354043302891319298)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def json_to_dict(result_set):\n",
    "    tweets = []\n",
    "    for index in range(0, len(result_set)):\n",
    "        status = result_set[index]\n",
    "        json_str = json.dumps(status._json)\n",
    "        tweet_dict = json.loads(json_str)\n",
    "        tweets.append(tweet_dict)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_dict_1 = json_to_dict(results_1)\n",
    "tweets_dict_2 = json_to_dict(results_2)\n",
    "tweets_dict_3 = json_to_dict(results_3)\n",
    "tweets_dict_4 = json_to_dict(results_4)\n",
    "tweets_dict_5 = json_to_dict(results_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_tweets_information(tweets_dict):\n",
    "    \n",
    "    new_tweets_dict = {'date_created': [],'tweet_text': [], \n",
    "                       'tweet_id': [], 'hashtags': [], \n",
    "                       'user_id': [], 'location': [], \n",
    "                       'retweeted': [],'lang': [],\n",
    "                       'retweeted_text': [],'retweeted_hashtags': []}\n",
    "\n",
    "    for tweet in tweets_dict:\n",
    "\n",
    "        date_created = tweet['created_at']\n",
    "        new_tweets_dict['date_created'].append(date_created)\n",
    "\n",
    "        tweet_id = tweet['id']\n",
    "        new_tweets_dict['tweet_id'].append(tweet_id)\n",
    "\n",
    "        tweet_text = tweet['text']\n",
    "        new_tweets_dict['tweet_text'].append(tweet_text)\n",
    "\n",
    "        #Getting the hashtags\n",
    "        hashtags_list = []\n",
    "        for hashtag in tweet['entities']['hashtags']:\n",
    "            hashtag = hashtag['text']\n",
    "            hashtags_list.append(hashtag)\n",
    "        new_tweets_dict['hashtags'].append(hashtags_list)\n",
    "\n",
    "        user_id = tweet['user']['id']\n",
    "        new_tweets_dict['user_id'].append(user_id)\n",
    "\n",
    "        location = tweet['user']['location']\n",
    "        new_tweets_dict['location'].append(location)\n",
    "        \n",
    "\n",
    "        lang =  tweet['lang']\n",
    "        new_tweets_dict['lang'].append(lang)\n",
    "        \n",
    "        if 'retweeted_status' in tweet:\n",
    "            retweet_text = tweet['retweeted_status']['text']\n",
    "            new_tweets_dict['retweeted'].append(True)\n",
    "            new_tweets_dict['retweeted_text'].append(retweet_text)\n",
    "            \n",
    "            retweet_hashtags_list = []\n",
    "            for text in tweet['retweeted_status']['entities']['hashtags']:\n",
    "                hashtag = text['text']\n",
    "                retweet_hashtags_list.append(hashtag)\n",
    "            new_tweets_dict['retweeted_hashtags'].append(retweet_hashtags_list)\n",
    "        \n",
    "        else:\n",
    "            new_tweets_dict['retweeted'].append(False)\n",
    "            new_tweets_dict['retweeted_text'].append(np.nan)\n",
    "            new_tweets_dict['retweeted_hashtags'].append(np.nan)\n",
    "            \n",
    "    return new_tweets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_tweets_dict = get_tweets_information(tweets_dict)\n",
    "df = pd.DataFrame.from_dict(new_tweets_dict)\n",
    "new_tweets_dict_2 = get_tweets_information(tweets_dict_2)\n",
    "df2 = pd.DataFrame.from_dict(new_tweets_dict_2)\n",
    "new_tweets_dict_3 = get_tweets_information(tweets_dict_3)\n",
    "df3 = pd.DataFrame.from_dict(new_tweets_dict_3)\n",
    "new_tweets_dict_4 = get_tweets_information(tweets_dict_4)\n",
    "df4 = pd.DataFrame.from_dict(new_tweets_dict_4)\n",
    "new_tweets_dict_5 = get_tweets_information(tweets_dict_5)\n",
    "df5 = pd.DataFrame.from_dict(new_tweets_dict_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df2, df3, df4, df5], axis = 'index', ignore_index = True)\n",
    "df.to_csv('kdrama_tweets', index = False)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Nadine Mukondiwa"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
